import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
import os
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langgraph.checkpoint import MemorySaver
from typing import Dict, Any, TypedDict

# API í‚¤ ì„¤ì • (ë¡œì»¬ê³¼ Streamlit Cloud í™˜ê²½ ëª¨ë‘ ì§€ì›)
load_dotenv()
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
api_key = os.environ.get("OPENAI_API_KEY")

# ê°ì • ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
negative_emotions = ["í™”ë‚˜", "ìŠ¬í”„", "ì†ìƒ", "ìš°ìš¸", "ë¶ˆì•ˆ", "ê±±ì •", "ì§œì¦", "í˜ë“¤"]
positive_emotions = ["ê¸°ì˜", "í–‰ë³µ", "ì¦ê²", "ì‹ ë‚˜", "ì„¤ë ˆ", "ì¢‹ì•„", "ì¬ë¯¸"]

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ChaCha - ì•„ì´ë“¤ì„ ìœ„í•œ ê°ì • ëŒ€í™” ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ChaChaì™€ ëŒ€í™”í•˜ê¸° ğŸ¤–")

# OpenAI API ì´ˆê¸°í™”
try:
    if not api_key:
        st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë‚˜ secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        llm = None
    else:
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            api_key=api_key
        )
except Exception as e:
    st.error(f"API ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
    llm = None

# ëŒ€í™” ìƒíƒœ ì •ì˜
class State(TypedDict):
    messages: list
    phase: str
    user_name: str
    user_age: int
    emotion_detected: str
    share_stage: str

# ì´ˆê¸° ìƒíƒœ ì„¤ì •
if "state" not in st.session_state:
    st.session_state.state = {
        "messages": [],
        "phase": "intro",
        "user_name": "ì¹œêµ¬",
        "user_age": 10,
        "emotion_detected": None,
        "share_stage": None
    }

# LangGraph ê·¸ë˜í”„ ë¹Œë”
builder = StateGraph(State)

# ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
def intro_node(state: State) -> Dict[str, Any]:
    system_prompt = (
        f"ë„ˆëŠ” ì•„ì´ì˜ ì¹œêµ¬ê°™ì€ ì±—ë´‡ ChaChaì•¼. ì•„ì´ì˜ ì´ë¦„ì€ {state['user_name']}ì´ê³ , ë‚˜ì´ëŠ” {state['user_age']}ì‚´ì´ì•¼. "
        f"ìš°ì„  ë°ê²Œ ì¸ì‚¬í•˜ê³  ì•„ì´ì˜ ê´€ì‹¬ì‚¬ë‚˜ ì·¨ë¯¸ë¥¼ ë¬¼ì–´ë´ì¤˜."
    )
    messages = [SystemMessage(content=system_prompt)]
    response = llm.invoke(messages)
    return {"messages": [AIMessage(content=response.content)], "phase": "explore"}

def explore_node(state: State) -> Dict[str, Any]:
    system_prompt = (
        "ì´ì œ ì•„ì´ê°€ ê´€ì‹¬ì‚¬ì— ëŒ€í•´ ë‹µí–ˆìœ¼ë¯€ë¡œ, ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼ì´ë‚˜ ìµœê·¼ ê²½í—˜ì„ ë¬¼ì–´ë³´ê³  ê·¸ë•Œ ëŠë‚€ ê°ì •ì„ ì§ˆë¬¸í•˜ì„¸ìš”. "
        "ì˜ˆë¥¼ ë“¤ë©´: 'ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ì´ ìˆì—ˆì–´? ê·¸ë•Œ ì–´ë–¤ ê¸°ë¶„ì´ ë“¤ì—ˆë‹ˆ?'"
    )
    messages = state["messages"] + [SystemMessage(content=system_prompt)]
    response = llm.invoke(messages)
    return {"messages": [AIMessage(content=response.content)], "phase": "label"}

def label_node(state: State) -> Dict[str, Any]:
    user_input = state["messages"][-1].content
    emotion_found = None
    for word in negative_emotions + positive_emotions:
        if word in user_input:
            emotion_found = word
            break
    if emotion_found:
        is_negative = any(word in emotion_found for word in negative_emotions)
        emotion_type = "negative" if is_negative else "positive"
        system_prompt = (
            f"ì‚¬ìš©ìê°€ ë°©ê¸ˆ ìì‹ ì˜ ê°ì •ì„ í‘œí˜„í–ˆìŠµë‹ˆë‹¤ ({emotion_found}). "
            f"ì´ë¥¼ ê³µê°í•˜ë©° ë°›ì•„ì£¼ê³ , í˜¹ì‹œ ë‹¤ë¥¸ ê°ì •ì€ ì—†ì—ˆëŠ”ì§€ ë¬¼ì–´ë³´ì„¸ìš”."
        )
        next_phase = "find" if emotion_type == "negative" else "record"
        messages = state["messages"] + [SystemMessage(content=system_prompt)]
        response = llm.invoke(messages)
        return {"messages": [AIMessage(content=response.content)], "emotion_detected": emotion_type, "phase": next_phase}
    else:
        system_prompt = (
            "ì‚¬ìš©ìê°€ ìì‹ ì˜ ê°ì •ì„ ëª…í™•íˆ ë§í•˜ì§€ ì•Šì•˜ì–´ìš”. "
            "ChaChaë¡œì„œ ì•„ì´ê°€ ëŠê¼ˆì„ ë§Œí•œ ê°ì •ì„ ë‘ì„¸ ê°€ì§€ ì œì‹œí•˜ë©´ì„œ ì–´ë–¤ ê°ì •ì´ ê°€ì¥ ê°€ê¹Œìš´ì§€ ë¬¼ì–´ë³´ì„¸ìš”."
        )
        messages = state["messages"] + [SystemMessage(content=system_prompt)]
        response = llm.invoke(messages)
        return {"messages": [AIMessage(content=response.content)]}

def find_node(state: State) -> Dict[str, Any]:
    system_prompt = (
        "ì´ì œ ì•„ì´ê°€ ë¶€ì •ì ì¸ ê°ì •ì„ ëŠê¼ˆìœ¼ë‹ˆ, ê·¸ ê°ì •ì„ ëœì–´ì¤„ ë°©ë²•ì„ í•¨ê»˜ ì°¾ì•„ë³´ë ¤ê³  í•´. "
        "ì•„ì´ì˜ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ, ë‹¤ìŒì— ë¹„ìŠ·í•œ ì¼ì´ ì¼ì–´ë‚¬ì„ ë•Œ ê¸°ë¶„ì´ ì¢‹ì•„ì§ˆ ìˆ˜ ìˆëŠ” í•´ê²°ì±…ì´ë‚˜ í–‰ë™ì„ 2~3ê°€ì§€ ì œì•ˆí•´ì¤˜."
    )
    messages = state["messages"] + [SystemMessage(content=system_prompt)]
    response = llm.invoke(messages)
    return {"messages": [AIMessage(content=response.content)], "phase": "share"}

def record_node(state: State) -> Dict[str, Any]:
    system_prompt = (
        "ì•„ì´ì˜ ê²½í—˜ì—ì„œ ê¸ì •ì ì¸ ê°ì •ì„ ëŠê¼ˆì–´. ChaChaë¡œì„œ ì•„ì´ì—ê²Œ ê·¸ í–‰ë³µí–ˆë˜ ìˆœê°„ì„ ê¸°ë¡ìœ¼ë¡œ ë‚¨ê²¨ë‘ëŠ” ê²Œ ì™œ ì¢‹ì€ì§€ ì•Œë ¤ì£¼ê³  ë…ë ¤í•´ì¤˜. "
        "ì˜ˆë¥¼ ë“¤ë©´ ì‚¬ì§„ ì°ê¸°ë‚˜ ì¼ê¸° ì“°ê¸°ë¥¼ ì œì•ˆí•˜ë©´ì„œ."
    )
    messages = state["messages"] + [SystemMessage(content=system_prompt)]
    response = llm.invoke(messages)
    return {"messages": [AIMessage(content=response.content)], "phase": "share"}

def share_node(state: State) -> Dict[str, Any]:
    share_stage = state.get("share_stage")
    if share_stage is None:
        return {"messages": [AIMessage(content="ì´ ì´ì•¼ê¸° í˜¹ì‹œ ë¶€ëª¨ë‹˜ê»˜ë„ ë§ì”€ë“œë ¸ë‹ˆ?")], "share_stage": "ask_share"}
    elif share_stage == "ask_share":
        user_input = state["messages"][-1].content.lower()
        yes_answers = ["yes", "ë„¤", "ì˜ˆ", "ì‘", "ë§ì”€ë“œë ¸", "ì•Œë ¤ë“œë ¸"]
        no_answers = ["no", "ì•„ë‹ˆ", "ì•„ì§", "ì•ˆ í–ˆ", "ì•ˆí–ˆ"]
        if any(yes in user_input for yes in yes_answers):
            return {"messages": [AIMessage(content="ì •ë§ ì˜í–ˆì–´! ë¶€ëª¨ë‹˜ê»˜ ì´ì•¼ê¸°í•˜ë‹¤ë‹ˆ ìš©ê¸°ìˆêµ¬ë‚˜. ë¶€ëª¨ë‹˜ì€ ë­ë¼ê³  í•˜ì…¨ì–´? ì–´ë–¤ ì¼ì´ ìˆì—ˆëŠ”ì§€ ê¶ê¸ˆí•´.")], "share_stage": "ask_outcome"}
        elif any(no in user_input for no in no_answers):
            return {"messages": [AIMessage(content="ê´œì°®ì•„. ì–¸ì œë“  ì¤€ë¹„ë˜ë©´ ë¶€ëª¨ë‹˜ê»˜ ë§ì”€ë“œë¦¬ë©´ ì¢‹ì„ ê±°ì•¼. ë¶„ëª… ë„ì›€ì´ ë˜ì‹¤ ê±°ì•¼. í˜¹ì‹œ ë˜ ë‹¤ë¥¸ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ê³  ì‹¶ë‹ˆ?")], "share_stage": "ask_another"}
        else:
            return {"messages": [AIMessage(content="ë¶€ëª¨ë‹˜ê»˜ ì´ì•¼ê¸°í•˜ëŠ” ê²Œ ì‰½ì§€ ì•Šì„ ìˆ˜ë„ ìˆì§€ë§Œ, ë¶„ëª…íˆ ë„ì›€ë  ê±°ì•¼.\në‹¤ë¥¸ ê³µìœ í•˜ê³  ì‹¶ì€ ì´ì•¼ê¸°ê°€ ìˆì„ê¹Œ?")], "share_stage": "ask_another"}
    elif share_stage == "ask_outcome":
        return {"messages": [AIMessage(content="ê·¸ë ‡êµ¬ë‚˜. ê³µìœ í•´ì¤˜ì„œ ê³ ë§ˆì›Œ! ì´ì œ ë˜ ë‹¤ë¥¸ ì´ì•¼ê¸°ê°€ ìˆë‹ˆ? ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ëŒ€í™”ëŠ” ì—¬ê¸°ê¹Œì§€ í•˜ê³  ìš°ë¦° ì–¸ì œë“  ë‹¤ì‹œ ì´ì•¼ê¸°í•  ìˆ˜ ìˆì–´.")], "share_stage": "ask_another"}
    elif share_stage == "ask_another":
        user_input = state["messages"][-1].content.lower()
        if "yes" in user_input or "ë„¤" in user_input or "ì‘" in user_input or "ìˆì–´" in user_input:
            return {"phase": "explore", "share_stage": None}
        else:
            return {"phase": "end"}

def end_node(state: State) -> Dict[str, Any]:
    system_prompt = "ì•„ì´ì™€ì˜ ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì¸ì‚¬ë¥¼ í•´ì£¼ì„¸ìš”."
    messages = state["messages"] + [SystemMessage(content=system_prompt)]
    response = llm.invoke(messages)
    return {"messages": [AIMessage(content=response.content)]}

# ë…¸ë“œ ì¶”ê°€
builder.add_node("intro", intro_node)
builder.add_node("explore", explore_node)
builder.add_node("label", label_node)
builder.add_node("find", find_node)
builder.add_node("record", record_node)
builder.add_node("share", share_node)
builder.add_node("end", end_node)

# ì—£ì§€ ì •ì˜
builder.add_edge("intro", "explore")
builder.add_conditional_edges("explore", lambda state: "label")
builder.add_conditional_edges("label", lambda state: state["phase"])
builder.add_conditional_edges("find", lambda state: "share")
builder.add_conditional_edges("record", lambda state: "share")
builder.add_conditional_edges("share", lambda state: state["phase"] if state["phase"] == "end" else "share")
builder.add_edge("end", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = builder.compile(checkpointer=MemorySaver())

# Streamlitì—ì„œ ì‚¬ìš©í•  í•¨ìˆ˜
def run_graph(user_input: str):
    state = st.session_state.state
    state["messages"].append(HumanMessage(content=user_input))
    result = graph.invoke(state)
    st.session_state.state = result
    return result["messages"][-1].content

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.state.get("messages", []):
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.write(message.content)
    else:
        with st.chat_message("assistant"):
            st.write(message.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    with st.chat_message("user"):
        st.write(prompt)
    with st.chat_message("assistant"):
        with st.spinner("ChaChaê°€ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
            response = run_graph(prompt)
            st.write(response)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ëŒ€í™” ê´€ë¦¬")
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.state = {
            "messages": [],
            "phase": "intro",
            "user_name": "ì¹œêµ¬",
            "user_age": 10,
            "emotion_detected": None,
            "share_stage": None
        }
        st.rerun()

    st.header("ì‚¬ìš©ì ì •ë³´")
    new_name = st.text_input("ì´ë¦„", value=st.session_state.state["user_name"])
    new_age = st.number_input("ë‚˜ì´", min_value=1, max_value=20, value=st.session_state.state["user_age"])
    if new_name != st.session_state.state["user_name"] or new_age != st.session_state.state["user_age"]:
        st.session_state.state["user_name"] = new_name
        st.session_state.state["user_age"] = new_age